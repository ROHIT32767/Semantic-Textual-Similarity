{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgfignok5Z5j",
        "outputId": "14925ad0-6cb2-44a0-9264-395bff1c31f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (2.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (1.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (24.2)\n",
            "Requirement already satisfied: psutil in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.5.1+cpu)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.2.0)\n",
            "Requirement already satisfied: requests in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.0)\n",
            "Requirement already satisfied: networkx in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (70.0.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: datasets in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/abhinav/.pyenv/versions/3.12.8/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install 'accelerate>=0.26.0'\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "331-OUJs-L62"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bu3VfWoH6bij"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "wxeul7KC5Z5l",
        "outputId": "8c91a6d9-da56-4968-b0fb-ea0d42b3cb4e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df_raw = pd.read_csv('../../train.csv')\n",
        "test_df_raw = pd.read_csv('../../test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGeO3-0H5Z5l"
      },
      "source": [
        "# Prepare the ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "coElL2zS5Z5m",
        "outputId": "ab7353ff-129e-4771-f0ae-b2bdd5869431"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s1",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s2",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BERT",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CNN",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Doc2Vec",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "LSTM",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "RNN",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "7c53dd28-41e2-4b9e-8a19-a272869e0d16",
              "rows": [
                [
                  "0",
                  "sts_train_4024",
                  "Sudan Blocks YouTube Over Anti-Islam Film",
                  "Pakistan's PM orders YouTube halt over anti-Islam film",
                  "0.5599999999999999",
                  "0.5564231276512146",
                  "0.5732188",
                  "0.37477154",
                  "0.53231996",
                  "0.6305318"
                ],
                [
                  "1",
                  "sts_train_1409",
                  "A man riding a white horse.",
                  "A woman leading a white horse.",
                  "0.36",
                  "0.334312230348587",
                  "0.4944464",
                  "0.431345",
                  "0.35446522",
                  "0.46078417"
                ],
                [
                  "2",
                  "sts_train_3397",
                  "Mr Morse is charged with assault and Mr Darvish is charged with filing a false report.",
                  "His partner Bijan Darvish is charged with filing a false police report.",
                  "0.55",
                  "0.4695009291172027",
                  "0.5852904",
                  "0.6022504",
                  "0.5563046",
                  "0.50047785"
                ],
                [
                  "3",
                  "sts_train_1532",
                  "A girl playing is a pile of colorful balls.",
                  "A little girl plays in a pit of colorful balls.",
                  "1.0",
                  "1.0087584257125854",
                  "0.955592",
                  "0.8785266",
                  "0.9809867",
                  "0.9115018"
                ],
                [
                  "4",
                  "sick_train_1874",
                  "A person in a black jacket is doing tricks on a motorbike",
                  "A man in a black jacket is doing tricks on a motorbike",
                  "0.98",
                  "0.94328773021698",
                  "0.96665156",
                  "0.7248457",
                  "0.9738539",
                  "0.9607496"
                ],
                [
                  "5",
                  "sts_train_133",
                  "A man and woman are driving down the street in a jeep.",
                  "A man and woman are driving down the road in an open air vehicle.",
                  "0.8",
                  "0.9370699524879456",
                  "0.93984765",
                  "0.82426137",
                  "0.79508126",
                  "0.76460606"
                ],
                [
                  "6",
                  "sick_train_3487",
                  "The girl is riding the horse",
                  "The man is riding the horse",
                  "0.58",
                  "0.6170145869255066",
                  "0.8157351",
                  "0.6943394",
                  "0.57481885",
                  "0.6546574"
                ],
                [
                  "7",
                  "sick_train_896",
                  "A man elegantly dressed in black is wearing an elaborate black mask",
                  "A man dressed in black is wearing an elaborate black mask",
                  "0.94",
                  "0.9339637160301208",
                  "0.987939",
                  "0.6548047",
                  "0.9315308",
                  "0.9216378"
                ],
                [
                  "8",
                  "sick_train_1506",
                  "A woman is snowboarding down a railing in the snow",
                  "A man is skiing down a hill and over a red obstacle",
                  "0.52",
                  "0.5787654519081116",
                  "0.64371073",
                  "0.6170907",
                  "0.49306148",
                  "0.43947914"
                ],
                [
                  "9",
                  "sick_train_4760",
                  "A cluster of four brown dogs are playing in a field of brown grass",
                  "A group of four brown dogs are playing in a field of brown grass",
                  "0.96",
                  "0.9254925847053528",
                  "0.9663499",
                  "0.8498552",
                  "0.94909984",
                  "0.9397987"
                ],
                [
                  "10",
                  "sts_train_207",
                  "Two men are talking.",
                  "Two men are playing guitar.",
                  "0.3",
                  "0.4260843396186828",
                  "0.45129314",
                  "0.6563489",
                  "0.36981916",
                  "0.37469262"
                ],
                [
                  "11",
                  "sts_train_2680",
                  "He urged patience from Americans eager for the service, which is intended to block about 80 percent of telemarketing calls.",
                  "The free service was originally intended to block about 80 percent of telemarketer calls.",
                  "0.6000000000000001",
                  "0.638708770275116",
                  "0.67626685",
                  "0.7472316",
                  "0.5657197",
                  "0.6005275"
                ],
                [
                  "12",
                  "sts_train_1298",
                  "A black and white photo of a living room with a large window, sofa, and chair.",
                  "A black and white scene of a well furnished room with a view outlooking a forest.",
                  "0.6000000000000001",
                  "0.6775991320610046",
                  "0.6604142",
                  "0.59124833",
                  "0.58479553",
                  "0.56498945"
                ],
                [
                  "13",
                  "sts_train_3766",
                  "Greece bond exchange the largest debt restructuring in history",
                  "Greece secures biggest debt deal in history",
                  "0.5599999999999999",
                  "0.5527081489562988",
                  "0.68716294",
                  "0.5376173",
                  "0.54752",
                  "0.69353557"
                ],
                [
                  "14",
                  "sick_train_5313",
                  "The people are not sitting on a bench in front of a restaurant",
                  "The people are sitting on a bench in front of a restaurant",
                  "0.7",
                  "0.7895141243934631",
                  "0.81520283",
                  "0.7943433",
                  "0.7180517",
                  "0.74036866"
                ],
                [
                  "15",
                  "sts_train_4969",
                  "Death toll from Philippine earthquake rises to 185",
                  "Death toll from Philippines quake rises to 144",
                  "0.7200000000000001",
                  "0.6568516492843628",
                  "0.7933802",
                  "0.5919438",
                  "0.71010137",
                  "0.72385305"
                ],
                [
                  "16",
                  "sick_train_4918",
                  "Two white dogs are playing with a brown dog and a tennis ball",
                  "Two white dogs are playing with a brown dog and a ball",
                  "0.94",
                  "0.8559902906417847",
                  "0.8930133",
                  "0.83569837",
                  "0.9219729",
                  "0.9589568"
                ],
                [
                  "17",
                  "sick_train_2592",
                  "A white dog is standing on fallen leaves",
                  "One white dog is standing on the leaves on the ground",
                  "0.9",
                  "0.9761204123497008",
                  "0.8780923",
                  "0.7647917",
                  "0.8853178",
                  "0.9249096"
                ],
                [
                  "18",
                  "sick_train_5696",
                  "Two white dogs are not running together",
                  "Two white dogs are running together",
                  "0.6799999999999999",
                  "0.9143943190574646",
                  "0.77346116",
                  "0.853823",
                  "0.6391286",
                  "0.70923203"
                ],
                [
                  "19",
                  "sick_train_5767",
                  "A woman is putting make-up on",
                  "The woman is putting make-up on",
                  "0.96",
                  "0.9241626858711244",
                  "0.81202507",
                  "0.7128707",
                  "0.9794834",
                  "0.93287456"
                ],
                [
                  "20",
                  "sick_train_3470",
                  "A group of people is gathering at a stand at the fair",
                  "No group of people is gathering at a stand at the fair",
                  "0.92",
                  "0.9720367789268494",
                  "0.81740785",
                  "0.86518353",
                  "0.90454066",
                  "0.9323856"
                ],
                [
                  "21",
                  "sick_train_5117",
                  "A large dog and a small dog are standing next to the kitchen counter and are investigating",
                  "A large dog and a small dog is standing on the kitchen counter and investigate",
                  "0.8800000000000001",
                  "0.9211153984069824",
                  "0.8883659",
                  "0.7959195",
                  "0.87120336",
                  "0.8525065"
                ],
                [
                  "22",
                  "sick_train_2766",
                  "A man is drinking orange juice and walking on a sunny day",
                  "There is no man drinking orange juice and walking on a sunny day",
                  "0.74",
                  "0.8398764729499817",
                  "0.7909962",
                  "0.7816898",
                  "0.7383685",
                  "0.76066667"
                ],
                [
                  "23",
                  "sick_train_467",
                  "Two boys are doing martial arts on a blue mat",
                  "Two children in white outfits and red protective gear are sitting on a mat",
                  "0.62",
                  "0.705028772354126",
                  "0.8234468",
                  "0.680833",
                  "0.61157125",
                  "0.70811033"
                ],
                [
                  "24",
                  "sts_train_872",
                  "A man is frying a tortilla.",
                  "A person is performing a card trick.",
                  "0.0",
                  "0.1248091161251068",
                  "0.14981875",
                  "0.33014238",
                  "0.1287717",
                  "0.17533092"
                ],
                [
                  "25",
                  "sick_train_1635",
                  "A child is splashing in a pool for children and other kids are playing in the background",
                  "A child is splashing in a pool for children and other children are playing in the background",
                  "0.98",
                  "0.9371448755264282",
                  "0.9792766",
                  "0.82541347",
                  "0.9622249",
                  "0.9579744"
                ],
                [
                  "26",
                  "sts_train_1094",
                  "Two cats sitting together on the sofa looking out the window.",
                  "Two cats are looking at a window.",
                  "0.76",
                  "0.7554111480712891",
                  "0.73097545",
                  "0.6970109",
                  "0.72163963",
                  "0.6763139"
                ],
                [
                  "27",
                  "sick_train_6093",
                  "A man is missing the soccer ball",
                  "A man is performing tricks with a soccer ball",
                  "0.7",
                  "0.7063078284263611",
                  "0.72071195",
                  "0.7597745",
                  "0.6761665",
                  "0.7767937"
                ],
                [
                  "28",
                  "sick_train_6913",
                  "The men are not playing soccer",
                  "A man is riding a motorcycle",
                  "0.3",
                  "0.2217757403850555",
                  "0.38870504",
                  "0.40886754",
                  "0.28402185",
                  "0.2692821"
                ],
                [
                  "29",
                  "sts_train_455",
                  "A man is slicing a pepper.",
                  "A person cuts a big green pepper apart.",
                  "0.76",
                  "0.76487797498703",
                  "0.75897455",
                  "0.63742745",
                  "0.8007226",
                  "0.68754286"
                ],
                [
                  "30",
                  "sts_train_3256",
                  "The MDC called the strike to force Mr Mugabe to either resign or negotiate a settlement of the Zimbabwe crisis.",
                  "The MDC called the week-long protest to urge Mugabe either to resign or to negotiate a settlement of the crisis gripping the country.",
                  "0.8",
                  "0.7805148363113403",
                  "0.77466047",
                  "0.7300518",
                  "0.7984327",
                  "0.75780576"
                ],
                [
                  "31",
                  "sick_train_3666",
                  "A man with a white moustache is standing on a balcony and is looking at the road below",
                  "A man is leaning on the ledge of a balcony",
                  "0.76",
                  "0.7430674433708191",
                  "0.8057716",
                  "0.69585",
                  "0.7267762",
                  "0.7799898"
                ],
                [
                  "32",
                  "sts_train_3372",
                  "Pennsylvania, which has the most aggressive treatment program, is treating 548 of 8,030 inmates.",
                  "Texas, which has more than three times Michigan's inmate population, is treating 328 of its 16,298 infected inmates.",
                  "0.2666",
                  "0.2285282611846923",
                  "0.38154757",
                  "0.28323257",
                  "0.23595327",
                  "0.4222384"
                ],
                [
                  "33",
                  "sts_train_5574",
                  "Red Sox Beat Tigers 5-2 to Advance to World Series",
                  "Red Sox beat Tigers to reach World Series",
                  "0.8",
                  "0.8511307239532471",
                  "0.8376274",
                  "0.6435409",
                  "0.81477916",
                  "0.8516037"
                ],
                [
                  "34",
                  "sick_train_3291",
                  "The woman is sitting near a flower bed and is overlooking a tunnel",
                  "Two people are sitting on a bench",
                  "0.36",
                  "0.3228526413440704",
                  "0.39328155",
                  "0.4108339",
                  "0.34832138",
                  "0.38832536"
                ],
                [
                  "35",
                  "sick_train_1065",
                  "A man is not playing the drums",
                  "A man is playing the guitar",
                  "0.5599999999999999",
                  "0.5057161450386047",
                  "0.5976775",
                  "0.6537854",
                  "0.57992923",
                  "0.51185143"
                ],
                [
                  "36",
                  "sick_train_4318",
                  "The man is lifting weights",
                  "Weights are being lifted by the man",
                  "0.98",
                  "1.0562316179275513",
                  "1.0111089",
                  "0.74929076",
                  "0.9836893",
                  "0.9929377"
                ],
                [
                  "37",
                  "sts_train_3480",
                  "human rights violations in myanmar include summary executions, torture and the recruitment of child soldiers. ",
                  "these human rights violations include summary executions, torture and the recruitment of child",
                  "0.8400000000000001",
                  "0.8982694745063782",
                  "0.8153036",
                  "0.8833945",
                  "0.80703914",
                  "0.72666293"
                ],
                [
                  "38",
                  "sick_train_2653",
                  "A girl is falling asleep",
                  "A girl is waking up",
                  "0.6799999999999999",
                  "0.751846969127655",
                  "0.72875875",
                  "0.46680474",
                  "0.67336375",
                  "0.6919221"
                ],
                [
                  "39",
                  "sick_train_5466",
                  "A man is doing a skateboard trick on a park porch",
                  "A man is doing a trick on a skateboard",
                  "0.8800000000000001",
                  "0.8397294878959656",
                  "0.9548461",
                  "0.6928451",
                  "0.87243485",
                  "0.97139776"
                ],
                [
                  "40",
                  "sts_train_650",
                  "The woman is dicing onions.",
                  "A woman is cutting an onion.",
                  "0.8800000000000001",
                  "0.9591037631034852",
                  "0.819506",
                  "0.68018484",
                  "0.84706235",
                  "0.7764094"
                ],
                [
                  "41",
                  "sick_train_11",
                  "A couple of policewomen are singing karaoke",
                  "Two women are not dancing",
                  "0.42",
                  "0.3513421416282654",
                  "0.42911792",
                  "0.5468874",
                  "0.40552288",
                  "0.3100659"
                ],
                [
                  "42",
                  "sts_train_1784",
                  "a red and white race car racing on a dirt racetrack.",
                  "A person is riding a dirt bike in a race on a dirt track.",
                  "0.2799999999999999",
                  "0.2817250788211822",
                  "0.36278623",
                  "0.30820101",
                  "0.25913554",
                  "0.3958684"
                ],
                [
                  "43",
                  "sick_train_3971",
                  "Two women are wearing bikinis and are walking on the sand",
                  "There are no women wearing bikinis on the sandy beach",
                  "0.7",
                  "0.6790129542350769",
                  "0.721185",
                  "0.64989674",
                  "0.706849",
                  "0.69471633"
                ],
                [
                  "44",
                  "sts_train_4227",
                  "Germany warns Greece: No more money without reforms",
                  "Euro zone to Greece: No rescue without reforms",
                  "0.52",
                  "0.5646466612815857",
                  "0.6109259",
                  "0.61226934",
                  "0.49186802",
                  "0.48650044"
                ],
                [
                  "45",
                  "sts_train_5222",
                  "Obama condemns Egypt violence, cancels military exercises",
                  "Pakistan condemns violence in Egypt",
                  "0.16",
                  "0.1827541291713714",
                  "0.20206453",
                  "0.5515796",
                  "0.16382173",
                  "0.16144454"
                ],
                [
                  "46",
                  "sts_train_2215",
                  "I thought that was mostly just the Dutch.",
                  "It is mostly just the Dutch.",
                  "0.8",
                  "0.7515009641647339",
                  "0.7011234",
                  "0.644847",
                  "0.7701031",
                  "0.71593446"
                ],
                [
                  "47",
                  "sts_train_2233",
                  "Irreligion that does that I have a problem.",
                  "Religion that doesn't do that I don't have a problem with.",
                  "0.32",
                  "0.3700679242610931",
                  "0.35381868",
                  "0.23723324",
                  "0.30979818",
                  "0.40230054"
                ],
                [
                  "48",
                  "sts_train_2234",
                  "If I'm angry, it will show up in one of those scans..",
                  "If I'm hyper active, it will show up in one of those scans..",
                  "0.6400000000000001",
                  "0.693057119846344",
                  "0.76441145",
                  "0.58540887",
                  "0.6292051",
                  "0.7227387"
                ],
                [
                  "49",
                  "sick_train_1326",
                  "A horse and its rider are not leaping over a barrier",
                  "A horse is leaping a hurdle and has a rider on its back",
                  "0.92",
                  "0.9793878197669984",
                  "0.7975876",
                  "0.7653048",
                  "0.9473004",
                  "0.8375959"
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 12833
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>score</th>\n",
              "      <th>BERT</th>\n",
              "      <th>CNN</th>\n",
              "      <th>Doc2Vec</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sts_train_4024</td>\n",
              "      <td>Sudan Blocks YouTube Over Anti-Islam Film</td>\n",
              "      <td>Pakistan's PM orders YouTube halt over anti-Is...</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.556423</td>\n",
              "      <td>0.573219</td>\n",
              "      <td>0.374772</td>\n",
              "      <td>0.532320</td>\n",
              "      <td>0.630532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sts_train_1409</td>\n",
              "      <td>A man riding a white horse.</td>\n",
              "      <td>A woman leading a white horse.</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.334312</td>\n",
              "      <td>0.494446</td>\n",
              "      <td>0.431345</td>\n",
              "      <td>0.354465</td>\n",
              "      <td>0.460784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sts_train_3397</td>\n",
              "      <td>Mr Morse is charged with assault and Mr Darvis...</td>\n",
              "      <td>His partner Bijan Darvish is charged with fili...</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.469501</td>\n",
              "      <td>0.585290</td>\n",
              "      <td>0.602250</td>\n",
              "      <td>0.556305</td>\n",
              "      <td>0.500478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sts_train_1532</td>\n",
              "      <td>A girl playing is a pile of colorful balls.</td>\n",
              "      <td>A little girl plays in a pit of colorful balls.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.008758</td>\n",
              "      <td>0.955592</td>\n",
              "      <td>0.878527</td>\n",
              "      <td>0.980987</td>\n",
              "      <td>0.911502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sick_train_1874</td>\n",
              "      <td>A person in a black jacket is doing tricks on ...</td>\n",
              "      <td>A man in a black jacket is doing tricks on a m...</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.943288</td>\n",
              "      <td>0.966652</td>\n",
              "      <td>0.724846</td>\n",
              "      <td>0.973854</td>\n",
              "      <td>0.960750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12828</th>\n",
              "      <td>sick_train_6323</td>\n",
              "      <td>A player of soccer is scoring a goal</td>\n",
              "      <td>Soccer players are kicking a soccer ball into ...</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.823367</td>\n",
              "      <td>0.766068</td>\n",
              "      <td>0.600554</td>\n",
              "      <td>0.855742</td>\n",
              "      <td>0.956778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12829</th>\n",
              "      <td>sick_train_87</td>\n",
              "      <td>The man and woman are strolling</td>\n",
              "      <td>The man and woman are walking</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.919968</td>\n",
              "      <td>0.893222</td>\n",
              "      <td>0.670413</td>\n",
              "      <td>0.891996</td>\n",
              "      <td>0.763841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12830</th>\n",
              "      <td>sts_train_3897</td>\n",
              "      <td>S. Africa's former president Mandela discharge...</td>\n",
              "      <td>Mandela Discharged From Hospital</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.864671</td>\n",
              "      <td>0.897016</td>\n",
              "      <td>0.527709</td>\n",
              "      <td>0.810817</td>\n",
              "      <td>0.729604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12831</th>\n",
              "      <td>sick_train_718</td>\n",
              "      <td>A large brown cat is jumping over a red hurdle</td>\n",
              "      <td>A large brown dog is jumping over a red hurdle</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.742021</td>\n",
              "      <td>0.651751</td>\n",
              "      <td>0.863331</td>\n",
              "      <td>0.694979</td>\n",
              "      <td>0.733784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12832</th>\n",
              "      <td>sts_train_574</td>\n",
              "      <td>A girl makes up her bed.</td>\n",
              "      <td>A young girl makes her bed.</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.891920</td>\n",
              "      <td>0.866538</td>\n",
              "      <td>0.639912</td>\n",
              "      <td>0.843753</td>\n",
              "      <td>0.840203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12833 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id                                                 s1  \\\n",
              "0       sts_train_4024          Sudan Blocks YouTube Over Anti-Islam Film   \n",
              "1       sts_train_1409                        A man riding a white horse.   \n",
              "2       sts_train_3397  Mr Morse is charged with assault and Mr Darvis...   \n",
              "3       sts_train_1532        A girl playing is a pile of colorful balls.   \n",
              "4      sick_train_1874  A person in a black jacket is doing tricks on ...   \n",
              "...                ...                                                ...   \n",
              "12828  sick_train_6323               A player of soccer is scoring a goal   \n",
              "12829    sick_train_87                    The man and woman are strolling   \n",
              "12830   sts_train_3897  S. Africa's former president Mandela discharge...   \n",
              "12831   sick_train_718     A large brown cat is jumping over a red hurdle   \n",
              "12832    sts_train_574                           A girl makes up her bed.   \n",
              "\n",
              "                                                      s2  score      BERT  \\\n",
              "0      Pakistan's PM orders YouTube halt over anti-Is...   0.56  0.556423   \n",
              "1                         A woman leading a white horse.   0.36  0.334312   \n",
              "2      His partner Bijan Darvish is charged with fili...   0.55  0.469501   \n",
              "3        A little girl plays in a pit of colorful balls.   1.00  1.008758   \n",
              "4      A man in a black jacket is doing tricks on a m...   0.98  0.943288   \n",
              "...                                                  ...    ...       ...   \n",
              "12828  Soccer players are kicking a soccer ball into ...   0.86  0.823367   \n",
              "12829                      The man and woman are walking   0.90  0.919968   \n",
              "12830                   Mandela Discharged From Hospital   0.84  0.864671   \n",
              "12831     A large brown dog is jumping over a red hurdle   0.68  0.742021   \n",
              "12832                        A young girl makes her bed.   0.88  0.891920   \n",
              "\n",
              "            CNN   Doc2Vec      LSTM       RNN  \n",
              "0      0.573219  0.374772  0.532320  0.630532  \n",
              "1      0.494446  0.431345  0.354465  0.460784  \n",
              "2      0.585290  0.602250  0.556305  0.500478  \n",
              "3      0.955592  0.878527  0.980987  0.911502  \n",
              "4      0.966652  0.724846  0.973854  0.960750  \n",
              "...         ...       ...       ...       ...  \n",
              "12828  0.766068  0.600554  0.855742  0.956778  \n",
              "12829  0.893222  0.670413  0.891996  0.763841  \n",
              "12830  0.897016  0.527709  0.810817  0.729604  \n",
              "12831  0.651751  0.863331  0.694979  0.733784  \n",
              "12832  0.866538  0.639912  0.843753  0.840203  \n",
              "\n",
              "[12833 rows x 9 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Models = ['BERT', 'CNN', 'Doc2Vec', 'LSTM', 'RNN']\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for model in Models:\n",
        "    dfs.append(pd.read_csv(f'../{model}/Results/train.csv'))\n",
        "\n",
        "combined_df = pd.concat(\n",
        "    [df['predicted_similarity'].reset_index(drop=True) for df in dfs],\n",
        "    axis=1\n",
        ")\n",
        "combined_df.columns = Models\n",
        "\n",
        "train_df = pd.concat(\n",
        "    [train_df_raw, combined_df] ,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j5Tqoop45Z5n",
        "outputId": "cbdbeb5d-80ae-4a82-85e9-09bbfc20b450"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s1",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s2",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BERT",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "CNN",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Doc2Vec",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "LSTM",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "RNN",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "993d181b-4b20-4b4a-a58d-d7d062275bb1",
              "rows": [
                [
                  "0",
                  "sick_test_822",
                  "A woman is talking to a man",
                  "A man is talking to a woman",
                  "0.9",
                  "0.9745688438415528",
                  "0.95012903",
                  "0.703845",
                  "0.8527131",
                  "0.9134446"
                ],
                [
                  "1",
                  "sts_test_111",
                  "A man is putting garlic on some bread slices.",
                  "A man is sprinkling seasoning on several split and buttered loaves of bread.",
                  "0.4",
                  "0.691741943359375",
                  "0.7759352",
                  "0.4887342",
                  "0.77863467",
                  "0.6399465"
                ],
                [
                  "2",
                  "sts_test_502",
                  "A bike is next to a couple women.",
                  "A child next to a bike.",
                  "0.4",
                  "0.7651089429855347",
                  "0.7896409",
                  "0.3253677",
                  "0.7644662",
                  "0.70885044"
                ],
                [
                  "3",
                  "sick_test_1253",
                  "A man is playing a bamboo flute",
                  "A flute is being played by the man",
                  "0.86",
                  "0.964098870754242",
                  "0.99615824",
                  "0.6573001",
                  "0.7351836",
                  "0.95737904"
                ],
                [
                  "4",
                  "sick_test_1967",
                  "A woman on a rock is lying on a blanket and reading a book",
                  "A woman is rocking over a blanket lying on someone reading a book",
                  "0.54",
                  "0.9460808634757996",
                  "0.90364975",
                  "0.72482747",
                  "0.7299906",
                  "0.9174024"
                ],
                [
                  "5",
                  "sick_test_464",
                  "The small bee is landing on a bunch of yellow flowers",
                  "A bee is clinging to a yellow flower",
                  "0.72",
                  "0.7897123694419861",
                  "0.8454335",
                  "0.6984203",
                  "0.7867068",
                  "0.7448546"
                ],
                [
                  "6",
                  "sts_test_1066",
                  "Kids, adults, booksellers and postal workers all are preparing for \"Harry Potter and the Order of the Phoenix.\"",
                  "The crates are full of hardback copies of \"Harry Potter and the Order of the Phoenix.\"",
                  "0.44",
                  "0.5503799915313721",
                  "0.7131855",
                  "0.10548569",
                  "0.7083416",
                  "0.90042436"
                ],
                [
                  "7",
                  "sick_test_440",
                  "A woman in a bikini is pulling a dog on a leash at the beach",
                  "A woman in a bikini is pulling a cat on a leash at the beach",
                  "0.78",
                  "0.7523176074028015",
                  "0.90842706",
                  "0.584307",
                  "0.8530537",
                  "0.9371532"
                ],
                [
                  "8",
                  "sick_test_732",
                  "A crowd of people is near the water",
                  "A group of children wearing the same clothes is waiting at a gate and one is kissing the mother",
                  "0.32",
                  "0.469178169965744",
                  "0.4598325",
                  "0.6170286",
                  "0.37062514",
                  "0.43157417"
                ],
                [
                  "9",
                  "sick_test_997",
                  "A black dog and a small white and black dog are looking up at a kitchen countertop",
                  "A large dog and a small dog are standing next to the kitchen counter and are investigating",
                  "0.8400000000000001",
                  "0.6681010723114014",
                  "0.7213254",
                  "0.5887714",
                  "0.6057987",
                  "0.5970586"
                ],
                [
                  "10",
                  "sick_test_29",
                  "A child is amazedly experiencing a new world",
                  "A child is experiencing a new world",
                  "0.9",
                  "0.9821283221244812",
                  "0.9007193",
                  "0.66332775",
                  "0.65685785",
                  "0.92817783"
                ],
                [
                  "11",
                  "sick_test_139",
                  "The herd of caribous is crossing a road",
                  "The herd of caribous is not crossing a road",
                  "0.6799999999999999",
                  "0.8128095865249634",
                  "0.75611585",
                  "0.7457141",
                  "0.6532528",
                  "0.69428235"
                ],
                [
                  "12",
                  "sts_test_1060",
                  "Taiwan has attempted to gain observer status to the United Nations-affiliated WHO for seven years, but again was rebuffed March 19 at its annual conference in Geneva.",
                  "It has sought observer status for seven years, but was again rebuffed May 19 at the annual WHO conference in Geneva.",
                  "0.65",
                  "0.6053591370582581",
                  "0.7525308",
                  "0.8537221",
                  "0.7387496",
                  "0.67005825"
                ],
                [
                  "13",
                  "sick_test_1405",
                  "A light brown dog is running in the water",
                  "A tan dog is playing in the water on the bank of a pond",
                  "0.8",
                  "0.693382203578949",
                  "0.8677643",
                  "0.5711216",
                  "0.62522835",
                  "0.66572595"
                ],
                [
                  "14",
                  "sick_test_1415",
                  "A woman is taking eggs out of a bowl",
                  "A woman is placing skewers onto a rack",
                  "0.38",
                  "0.283557116985321",
                  "0.4131769",
                  "0.53678566",
                  "0.3695193",
                  "0.1776279"
                ],
                [
                  "15",
                  "sts_test_1319",
                  "What the Papers Say, Aug. 19, 2013",
                  "What the Papers Say, Dec. 30, 2013",
                  "0.534",
                  "0.4518528282642364",
                  "0.54496074",
                  "0.5676161",
                  "0.5793077",
                  "0.5428719"
                ],
                [
                  "16",
                  "sick_test_1412",
                  "Pedestrians and cars are moving through a traffic jam in a big city",
                  "Some people and vehicles are on a crowded street",
                  "0.64",
                  "0.8382599949836731",
                  "0.71868974",
                  "0.36894864",
                  "0.7620778",
                  "0.6916743"
                ],
                [
                  "17",
                  "sick_test_343",
                  "Two girls are playing guitar",
                  "Two men are talking",
                  "0.307",
                  "0.1787436753511428",
                  "0.1776644",
                  "0.43924338",
                  "0.5506456",
                  "0.23474649"
                ],
                [
                  "18",
                  "sick_test_436",
                  "A boy and a girl are naked",
                  "A boy and a girl in swimsuits are wearing arm floats",
                  "0.52",
                  "0.5309771299362183",
                  "0.6484933",
                  "0.63383406",
                  "0.5307679",
                  "0.57502383"
                ],
                [
                  "19",
                  "sick_test_763",
                  "A small man is sitting in a military accessories store",
                  "The person is slicing onions",
                  "0.2",
                  "0.2244737148284912",
                  "0.22828609",
                  "0.46148258",
                  "0.2763434",
                  "0.5581411"
                ],
                [
                  "20",
                  "sick_test_709",
                  "Runners are racing down a track",
                  "Men are running a race",
                  "0.78",
                  "0.7459227442741394",
                  "0.63598967",
                  "0.43152207",
                  "0.6826085",
                  "0.61926615"
                ],
                [
                  "21",
                  "sick_test_1457",
                  "A man and a child are kayaking through gentle waters",
                  "A yellow kayak is being ridden by a man and a young boy",
                  "0.8800000000000001",
                  "0.72077876329422",
                  "0.8835654",
                  "0.6511826",
                  "0.8026853",
                  "0.791174"
                ],
                [
                  "22",
                  "sick_test_1055",
                  "A woman on a boulder is lying on a blanket and reading a book",
                  "A seated woman is singing a song and playing the guitar",
                  "0.52",
                  "0.3981631100177765",
                  "0.3449719",
                  "0.4841662",
                  "0.3802997",
                  "0.48907447"
                ],
                [
                  "23",
                  "sts_test_558",
                  "Six children are cleaning a room.",
                  "Two male children cleaning up leaves in a parking lot.",
                  "0.32",
                  "0.4277808368206024",
                  "0.71816593",
                  "0.6191948",
                  "0.5785122",
                  "0.40590796"
                ],
                [
                  "24",
                  "sick_test_1319",
                  "Two little boys are playing outside with a soccer ball on the green grass",
                  "There are no little boys playing outside with a soccer ball on the green grass",
                  "0.64",
                  "0.8411417007446289",
                  "0.761821",
                  "0.79345393",
                  "0.75751024",
                  "0.9018142"
                ],
                [
                  "25",
                  "sick_test_344",
                  "The young boys are playing outdoors and the man is smiling nearby",
                  "There is no boy playing outdoors and there is no man smiling",
                  "0.72",
                  "0.926966428756714",
                  "0.7519666",
                  "0.64795697",
                  "0.62445897",
                  "0.7301833"
                ],
                [
                  "26",
                  "sick_test_323",
                  "Boys are dancing in front of some people",
                  "Two men are doing a funny skit with a boxer in front of a crowd of people",
                  "0.44",
                  "0.3026833534240722",
                  "0.58163404",
                  "0.52969",
                  "0.4995317",
                  "0.36579993"
                ],
                [
                  "27",
                  "sick_test_814",
                  "A woman is adding ingredients to a big bowl",
                  "A woman is cracking some eggs into a bowl",
                  "0.86",
                  "0.6002654433250427",
                  "0.5927037",
                  "0.4744203",
                  "0.49145705",
                  "0.7428195"
                ],
                [
                  "28",
                  "sick_test_132",
                  "Dirt bikers are not riding on a trail",
                  "Dirt bikers are riding on a trail",
                  "0.8",
                  "0.7789063453674316",
                  "0.7902297",
                  "0.7257083",
                  "0.87375677",
                  "0.8130713"
                ],
                [
                  "29",
                  "sts_test_1228",
                  "Nelson Mandela in Hospital for Tests",
                  "South Africa: Mandela in hospital for tests",
                  "0.92",
                  "0.9499765634536744",
                  "0.5182564",
                  "0.80664974",
                  "0.96310884",
                  "0.9445553"
                ],
                [
                  "30",
                  "sick_test_1514",
                  "A band is performing on a stage",
                  "A band is playing onstage",
                  "0.98",
                  "1.08297860622406",
                  "0.9839452",
                  "0.785486",
                  "0.9381515",
                  "0.8512072"
                ],
                [
                  "31",
                  "sick_test_1585",
                  "The man is cutting cooked octopus",
                  "A woman is chopping up an octopus",
                  "0.817",
                  "0.5959733128547668",
                  "0.668719",
                  "0.6718309",
                  "0.67923206",
                  "0.52023005"
                ],
                [
                  "32",
                  "sick_test_550",
                  "A middle eastern man is standing with the back against a lamp post near to other people",
                  "A middle eastern man is standing against a lamp post near to other people",
                  "0.9",
                  "0.9108361601829528",
                  "0.8989234",
                  "0.67936015",
                  "0.9029707",
                  "0.9449451"
                ],
                [
                  "33",
                  "sick_test_1851",
                  "A man is drawing",
                  "There is no man drawing",
                  "0.76",
                  "0.8327609896659851",
                  "0.7140718",
                  "0.7695144",
                  "0.7207827",
                  "0.6205169"
                ],
                [
                  "34",
                  "sick_test_509",
                  "A man in a hat is standing outside of a green jeep",
                  "A man in a hat is standing outside of a green vehicle",
                  "0.9",
                  "0.8797928690910339",
                  "1.0113719",
                  "0.6856836",
                  "0.8805904",
                  "0.82725245"
                ],
                [
                  "35",
                  "sts_test_75",
                  "The man is using a camera to hammer a nail.",
                  "Someone is banging a camera lense against a nail.",
                  "0.52",
                  "0.7750473022460938",
                  "0.7392763",
                  "0.68665916",
                  "0.544324",
                  "0.74275315"
                ],
                [
                  "36",
                  "sick_test_387",
                  "The person with the green shirt is jumping high over the grass",
                  "A young boy is jumping in the air with his knees bent and arms spread",
                  "0.6",
                  "0.6332209706306458",
                  "0.7784403",
                  "0.70777386",
                  "0.61119884",
                  "0.5879854"
                ],
                [
                  "37",
                  "sick_test_1911",
                  "A girl in a band is playing the flute",
                  "A girl in a band is playing an instrument",
                  "0.8800000000000001",
                  "0.8215572834014893",
                  "0.9180175",
                  "0.7238903",
                  "0.68785506",
                  "0.70292926"
                ],
                [
                  "38",
                  "sick_test_782",
                  "A yellow dog is running down a path covered by sand",
                  "A golden retriever is running",
                  "0.72",
                  "0.5727254748344421",
                  "0.74725133",
                  "0.76605505",
                  "0.7549649",
                  "0.74670506"
                ],
                [
                  "39",
                  "sick_test_417",
                  "A small dog is lying on a bed",
                  "A small dog is lying under the bed",
                  "0.62",
                  "0.9156191945075988",
                  "0.9191029",
                  "0.7668243",
                  "0.97928107",
                  "0.94613934"
                ],
                [
                  "40",
                  "sick_test_662",
                  "A man is not cutting a potato",
                  "A man is cutting a potato",
                  "0.72",
                  "0.8191822171211243",
                  "0.80011714",
                  "0.78711987",
                  "0.76836693",
                  "0.7044983"
                ],
                [
                  "41",
                  "sick_test_1037",
                  "A person is stupidly throwing a cat at the ceiling",
                  "A person is throwing a cat at the ceiling",
                  "0.8800000000000001",
                  "0.907307505607605",
                  "0.9766392",
                  "0.8902833",
                  "0.9624398",
                  "0.7656173"
                ],
                [
                  "42",
                  "sts_test_1302",
                  "Saudi Arabia gets a seat at the UN Security Council",
                  "Saudi Arabia rejects seat on UN Security Council",
                  "0.5599999999999999",
                  "0.6330841183662415",
                  "0.6765804",
                  "0.68899935",
                  "0.7100906",
                  "0.66238904"
                ],
                [
                  "43",
                  "sick_test_1524",
                  "Four people are difficultly walking with difficulty across thick snow and the sun is setting",
                  "Four people are walking across thick snow and the sun is setting",
                  "0.92",
                  "0.919081687927246",
                  "0.8866905",
                  "0.7316604",
                  "0.9016274",
                  "0.9358527"
                ],
                [
                  "44",
                  "sick_test_140",
                  "An old woman is wearing a rose patterned shirt and is clumsily carrying two newspapers",
                  "The woman is wearing sunglasses of large size and is holding newspapers in both hands",
                  "0.7",
                  "0.656484842300415",
                  "0.66675603",
                  "0.7206295",
                  "0.6852591",
                  "0.6211544"
                ],
                [
                  "45",
                  "sts_test_960",
                  "Martin, 58, will be freed today after serving two thirds of his five-year sentence for the manslaughter of 16-year-old Fred Barras.",
                  "Martin served two thirds of a five-year sentence for the manslaughter of Barras and for wounding Fearon.",
                  "0.6000000000000001",
                  "0.580322802066803",
                  "0.6846349",
                  "0.8140631",
                  "0.6634648",
                  "0.80948126"
                ],
                [
                  "46",
                  "sick_test_189",
                  "A small monkey is walking in the river",
                  "A small monkey is walking through water",
                  "0.86",
                  "0.8558796644210815",
                  "0.88776857",
                  "0.6255795",
                  "0.9660522",
                  "0.8547532"
                ],
                [
                  "47",
                  "sick_test_518",
                  "Some meat is being stitched together by a woman",
                  "Some meat is being cut into pieces by a woman",
                  "0.65",
                  "0.8556027412414551",
                  "0.93087155",
                  "0.5317743",
                  "0.73865676",
                  "0.9112269"
                ],
                [
                  "48",
                  "sick_test_607",
                  "The woman is chopping garlic",
                  "The woman is not chopping garlic",
                  "0.6",
                  "0.8609710335731506",
                  "0.73553777",
                  "0.86499715",
                  "0.5868356",
                  "0.6769096"
                ],
                [
                  "49",
                  "sick_test_1712",
                  "A surfer is leaning on a surfboard",
                  "The person is wearing a wetsuit and is riding a surfboard",
                  "0.597",
                  "0.6352059245109558",
                  "0.74751216",
                  "0.5886889",
                  "0.7607863",
                  "0.704167"
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 3347
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>score</th>\n",
              "      <th>BERT</th>\n",
              "      <th>CNN</th>\n",
              "      <th>Doc2Vec</th>\n",
              "      <th>LSTM</th>\n",
              "      <th>RNN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sick_test_822</td>\n",
              "      <td>A woman is talking to a man</td>\n",
              "      <td>A man is talking to a woman</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.974569</td>\n",
              "      <td>0.950129</td>\n",
              "      <td>0.703845</td>\n",
              "      <td>0.852713</td>\n",
              "      <td>0.913445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sts_test_111</td>\n",
              "      <td>A man is putting garlic on some bread slices.</td>\n",
              "      <td>A man is sprinkling seasoning on several split...</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.691742</td>\n",
              "      <td>0.775935</td>\n",
              "      <td>0.488734</td>\n",
              "      <td>0.778635</td>\n",
              "      <td>0.639946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sts_test_502</td>\n",
              "      <td>A bike is next to a couple women.</td>\n",
              "      <td>A child next to a bike.</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.765109</td>\n",
              "      <td>0.789641</td>\n",
              "      <td>0.325368</td>\n",
              "      <td>0.764466</td>\n",
              "      <td>0.708850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sick_test_1253</td>\n",
              "      <td>A man is playing a bamboo flute</td>\n",
              "      <td>A flute is being played by the man</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.964099</td>\n",
              "      <td>0.996158</td>\n",
              "      <td>0.657300</td>\n",
              "      <td>0.735184</td>\n",
              "      <td>0.957379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sick_test_1967</td>\n",
              "      <td>A woman on a rock is lying on a blanket and re...</td>\n",
              "      <td>A woman is rocking over a blanket lying on som...</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.946081</td>\n",
              "      <td>0.903650</td>\n",
              "      <td>0.724827</td>\n",
              "      <td>0.729991</td>\n",
              "      <td>0.917402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3342</th>\n",
              "      <td>sick_test_1099</td>\n",
              "      <td>A woman is collecting tap water in a mug</td>\n",
              "      <td>There is no boy filling a pitcher with water</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.498875</td>\n",
              "      <td>0.613817</td>\n",
              "      <td>0.578613</td>\n",
              "      <td>0.559423</td>\n",
              "      <td>0.239837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3343</th>\n",
              "      <td>sts_test_559</td>\n",
              "      <td>There is a cook preparing food.</td>\n",
              "      <td>A cook is making food.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.987018</td>\n",
              "      <td>0.885129</td>\n",
              "      <td>0.571081</td>\n",
              "      <td>0.897953</td>\n",
              "      <td>0.704321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3344</th>\n",
              "      <td>sick_test_1212</td>\n",
              "      <td>A young boy is playing a guitar</td>\n",
              "      <td>A boy is playing guitar</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.898162</td>\n",
              "      <td>0.973016</td>\n",
              "      <td>0.782884</td>\n",
              "      <td>0.878593</td>\n",
              "      <td>0.983629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3345</th>\n",
              "      <td>sick_test_1101</td>\n",
              "      <td>A dog, which is small, is playing on the green...</td>\n",
              "      <td>A dog is near a ball colored in red, which is ...</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.602705</td>\n",
              "      <td>0.801525</td>\n",
              "      <td>0.504830</td>\n",
              "      <td>0.521849</td>\n",
              "      <td>0.635977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3346</th>\n",
              "      <td>sts_test_881</td>\n",
              "      <td>Bremer said one initiative is to launch a US$7...</td>\n",
              "      <td>Bremer said he would launch a $70-million prog...</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.670134</td>\n",
              "      <td>0.746305</td>\n",
              "      <td>0.733813</td>\n",
              "      <td>0.686617</td>\n",
              "      <td>0.638007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3347 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id                                                 s1  \\\n",
              "0      sick_test_822                        A woman is talking to a man   \n",
              "1       sts_test_111      A man is putting garlic on some bread slices.   \n",
              "2       sts_test_502                  A bike is next to a couple women.   \n",
              "3     sick_test_1253                    A man is playing a bamboo flute   \n",
              "4     sick_test_1967  A woman on a rock is lying on a blanket and re...   \n",
              "...              ...                                                ...   \n",
              "3342  sick_test_1099           A woman is collecting tap water in a mug   \n",
              "3343    sts_test_559                    There is a cook preparing food.   \n",
              "3344  sick_test_1212                    A young boy is playing a guitar   \n",
              "3345  sick_test_1101  A dog, which is small, is playing on the green...   \n",
              "3346    sts_test_881  Bremer said one initiative is to launch a US$7...   \n",
              "\n",
              "                                                     s2  score      BERT  \\\n",
              "0                           A man is talking to a woman   0.90  0.974569   \n",
              "1     A man is sprinkling seasoning on several split...   0.40  0.691742   \n",
              "2                               A child next to a bike.   0.40  0.765109   \n",
              "3                    A flute is being played by the man   0.86  0.964099   \n",
              "4     A woman is rocking over a blanket lying on som...   0.54  0.946081   \n",
              "...                                                 ...    ...       ...   \n",
              "3342       There is no boy filling a pitcher with water   0.52  0.498875   \n",
              "3343                             A cook is making food.   1.00  0.987018   \n",
              "3344                            A boy is playing guitar   0.86  0.898162   \n",
              "3345  A dog is near a ball colored in red, which is ...   0.48  0.602705   \n",
              "3346  Bremer said he would launch a $70-million prog...   0.72  0.670134   \n",
              "\n",
              "           CNN   Doc2Vec      LSTM       RNN  \n",
              "0     0.950129  0.703845  0.852713  0.913445  \n",
              "1     0.775935  0.488734  0.778635  0.639946  \n",
              "2     0.789641  0.325368  0.764466  0.708850  \n",
              "3     0.996158  0.657300  0.735184  0.957379  \n",
              "4     0.903650  0.724827  0.729991  0.917402  \n",
              "...        ...       ...       ...       ...  \n",
              "3342  0.613817  0.578613  0.559423  0.239837  \n",
              "3343  0.885129  0.571081  0.897953  0.704321  \n",
              "3344  0.973016  0.782884  0.878593  0.983629  \n",
              "3345  0.801525  0.504830  0.521849  0.635977  \n",
              "3346  0.746305  0.733813  0.686617  0.638007  \n",
              "\n",
              "[3347 rows x 9 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs = []\n",
        "\n",
        "for model_names in Models:\n",
        "    dfs.append(pd.read_csv(f'../{model_names}/Results/test.csv'))\n",
        "\n",
        "combined_df = pd.concat(\n",
        "    [df['predicted_similarity'].reset_index(drop=True) for df in dfs],\n",
        "    axis=1\n",
        ")\n",
        "combined_df.columns = Models\n",
        "\n",
        "test_df = pd.concat(\n",
        "    [test_df_raw, combined_df],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcfjeYmA5Z5n"
      },
      "source": [
        "## Specific to BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Di8-Nal05Z5n",
        "outputId": "0d767766-7af7-4204-8295-1452e19cb8a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s1",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s2",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BERT",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "c44e3177-826e-47d0-a32d-f818b421d54d",
              "rows": [
                [
                  "0",
                  "sts_train_4024",
                  "Sudan Blocks YouTube Over Anti-Islam Film",
                  "Pakistan's PM orders YouTube halt over anti-Islam film",
                  "0.5599999999999999",
                  "0.5564231276512146"
                ],
                [
                  "1",
                  "sts_train_1409",
                  "A man riding a white horse.",
                  "A woman leading a white horse.",
                  "0.36",
                  "0.334312230348587"
                ],
                [
                  "2",
                  "sts_train_3397",
                  "Mr Morse is charged with assault and Mr Darvish is charged with filing a false report.",
                  "His partner Bijan Darvish is charged with filing a false police report.",
                  "0.55",
                  "0.4695009291172027"
                ],
                [
                  "3",
                  "sts_train_1532",
                  "A girl playing is a pile of colorful balls.",
                  "A little girl plays in a pit of colorful balls.",
                  "1.0",
                  "1.0087584257125854"
                ],
                [
                  "4",
                  "sick_train_1874",
                  "A person in a black jacket is doing tricks on a motorbike",
                  "A man in a black jacket is doing tricks on a motorbike",
                  "0.98",
                  "0.94328773021698"
                ],
                [
                  "5",
                  "sts_train_133",
                  "A man and woman are driving down the street in a jeep.",
                  "A man and woman are driving down the road in an open air vehicle.",
                  "0.8",
                  "0.9370699524879456"
                ],
                [
                  "6",
                  "sick_train_3487",
                  "The girl is riding the horse",
                  "The man is riding the horse",
                  "0.58",
                  "0.6170145869255066"
                ],
                [
                  "7",
                  "sick_train_896",
                  "A man elegantly dressed in black is wearing an elaborate black mask",
                  "A man dressed in black is wearing an elaborate black mask",
                  "0.94",
                  "0.9339637160301208"
                ],
                [
                  "8",
                  "sick_train_1506",
                  "A woman is snowboarding down a railing in the snow",
                  "A man is skiing down a hill and over a red obstacle",
                  "0.52",
                  "0.5787654519081116"
                ],
                [
                  "9",
                  "sick_train_4760",
                  "A cluster of four brown dogs are playing in a field of brown grass",
                  "A group of four brown dogs are playing in a field of brown grass",
                  "0.96",
                  "0.9254925847053528"
                ],
                [
                  "10",
                  "sts_train_207",
                  "Two men are talking.",
                  "Two men are playing guitar.",
                  "0.3",
                  "0.4260843396186828"
                ],
                [
                  "11",
                  "sts_train_2680",
                  "He urged patience from Americans eager for the service, which is intended to block about 80 percent of telemarketing calls.",
                  "The free service was originally intended to block about 80 percent of telemarketer calls.",
                  "0.6000000000000001",
                  "0.638708770275116"
                ],
                [
                  "12",
                  "sts_train_1298",
                  "A black and white photo of a living room with a large window, sofa, and chair.",
                  "A black and white scene of a well furnished room with a view outlooking a forest.",
                  "0.6000000000000001",
                  "0.6775991320610046"
                ],
                [
                  "13",
                  "sts_train_3766",
                  "Greece bond exchange the largest debt restructuring in history",
                  "Greece secures biggest debt deal in history",
                  "0.5599999999999999",
                  "0.5527081489562988"
                ],
                [
                  "14",
                  "sick_train_5313",
                  "The people are not sitting on a bench in front of a restaurant",
                  "The people are sitting on a bench in front of a restaurant",
                  "0.7",
                  "0.7895141243934631"
                ],
                [
                  "15",
                  "sts_train_4969",
                  "Death toll from Philippine earthquake rises to 185",
                  "Death toll from Philippines quake rises to 144",
                  "0.7200000000000001",
                  "0.6568516492843628"
                ],
                [
                  "16",
                  "sick_train_4918",
                  "Two white dogs are playing with a brown dog and a tennis ball",
                  "Two white dogs are playing with a brown dog and a ball",
                  "0.94",
                  "0.8559902906417847"
                ],
                [
                  "17",
                  "sick_train_2592",
                  "A white dog is standing on fallen leaves",
                  "One white dog is standing on the leaves on the ground",
                  "0.9",
                  "0.9761204123497008"
                ],
                [
                  "18",
                  "sick_train_5696",
                  "Two white dogs are not running together",
                  "Two white dogs are running together",
                  "0.6799999999999999",
                  "0.9143943190574646"
                ],
                [
                  "19",
                  "sick_train_5767",
                  "A woman is putting make-up on",
                  "The woman is putting make-up on",
                  "0.96",
                  "0.9241626858711244"
                ],
                [
                  "20",
                  "sick_train_3470",
                  "A group of people is gathering at a stand at the fair",
                  "No group of people is gathering at a stand at the fair",
                  "0.92",
                  "0.9720367789268494"
                ],
                [
                  "21",
                  "sick_train_5117",
                  "A large dog and a small dog are standing next to the kitchen counter and are investigating",
                  "A large dog and a small dog is standing on the kitchen counter and investigate",
                  "0.8800000000000001",
                  "0.9211153984069824"
                ],
                [
                  "22",
                  "sick_train_2766",
                  "A man is drinking orange juice and walking on a sunny day",
                  "There is no man drinking orange juice and walking on a sunny day",
                  "0.74",
                  "0.8398764729499817"
                ],
                [
                  "23",
                  "sick_train_467",
                  "Two boys are doing martial arts on a blue mat",
                  "Two children in white outfits and red protective gear are sitting on a mat",
                  "0.62",
                  "0.705028772354126"
                ],
                [
                  "24",
                  "sts_train_872",
                  "A man is frying a tortilla.",
                  "A person is performing a card trick.",
                  "0.0",
                  "0.1248091161251068"
                ],
                [
                  "25",
                  "sick_train_1635",
                  "A child is splashing in a pool for children and other kids are playing in the background",
                  "A child is splashing in a pool for children and other children are playing in the background",
                  "0.98",
                  "0.9371448755264282"
                ],
                [
                  "26",
                  "sts_train_1094",
                  "Two cats sitting together on the sofa looking out the window.",
                  "Two cats are looking at a window.",
                  "0.76",
                  "0.7554111480712891"
                ],
                [
                  "27",
                  "sick_train_6093",
                  "A man is missing the soccer ball",
                  "A man is performing tricks with a soccer ball",
                  "0.7",
                  "0.7063078284263611"
                ],
                [
                  "28",
                  "sick_train_6913",
                  "The men are not playing soccer",
                  "A man is riding a motorcycle",
                  "0.3",
                  "0.2217757403850555"
                ],
                [
                  "29",
                  "sts_train_455",
                  "A man is slicing a pepper.",
                  "A person cuts a big green pepper apart.",
                  "0.76",
                  "0.76487797498703"
                ],
                [
                  "30",
                  "sts_train_3256",
                  "The MDC called the strike to force Mr Mugabe to either resign or negotiate a settlement of the Zimbabwe crisis.",
                  "The MDC called the week-long protest to urge Mugabe either to resign or to negotiate a settlement of the crisis gripping the country.",
                  "0.8",
                  "0.7805148363113403"
                ],
                [
                  "31",
                  "sick_train_3666",
                  "A man with a white moustache is standing on a balcony and is looking at the road below",
                  "A man is leaning on the ledge of a balcony",
                  "0.76",
                  "0.7430674433708191"
                ],
                [
                  "32",
                  "sts_train_3372",
                  "Pennsylvania, which has the most aggressive treatment program, is treating 548 of 8,030 inmates.",
                  "Texas, which has more than three times Michigan's inmate population, is treating 328 of its 16,298 infected inmates.",
                  "0.2666",
                  "0.2285282611846923"
                ],
                [
                  "33",
                  "sts_train_5574",
                  "Red Sox Beat Tigers 5-2 to Advance to World Series",
                  "Red Sox beat Tigers to reach World Series",
                  "0.8",
                  "0.8511307239532471"
                ],
                [
                  "34",
                  "sick_train_3291",
                  "The woman is sitting near a flower bed and is overlooking a tunnel",
                  "Two people are sitting on a bench",
                  "0.36",
                  "0.3228526413440704"
                ],
                [
                  "35",
                  "sick_train_1065",
                  "A man is not playing the drums",
                  "A man is playing the guitar",
                  "0.5599999999999999",
                  "0.5057161450386047"
                ],
                [
                  "36",
                  "sick_train_4318",
                  "The man is lifting weights",
                  "Weights are being lifted by the man",
                  "0.98",
                  "1.0562316179275513"
                ],
                [
                  "37",
                  "sts_train_3480",
                  "human rights violations in myanmar include summary executions, torture and the recruitment of child soldiers. ",
                  "these human rights violations include summary executions, torture and the recruitment of child",
                  "0.8400000000000001",
                  "0.8982694745063782"
                ],
                [
                  "38",
                  "sick_train_2653",
                  "A girl is falling asleep",
                  "A girl is waking up",
                  "0.6799999999999999",
                  "0.751846969127655"
                ],
                [
                  "39",
                  "sick_train_5466",
                  "A man is doing a skateboard trick on a park porch",
                  "A man is doing a trick on a skateboard",
                  "0.8800000000000001",
                  "0.8397294878959656"
                ],
                [
                  "40",
                  "sts_train_650",
                  "The woman is dicing onions.",
                  "A woman is cutting an onion.",
                  "0.8800000000000001",
                  "0.9591037631034852"
                ],
                [
                  "41",
                  "sick_train_11",
                  "A couple of policewomen are singing karaoke",
                  "Two women are not dancing",
                  "0.42",
                  "0.3513421416282654"
                ],
                [
                  "42",
                  "sts_train_1784",
                  "a red and white race car racing on a dirt racetrack.",
                  "A person is riding a dirt bike in a race on a dirt track.",
                  "0.2799999999999999",
                  "0.2817250788211822"
                ],
                [
                  "43",
                  "sick_train_3971",
                  "Two women are wearing bikinis and are walking on the sand",
                  "There are no women wearing bikinis on the sandy beach",
                  "0.7",
                  "0.6790129542350769"
                ],
                [
                  "44",
                  "sts_train_4227",
                  "Germany warns Greece: No more money without reforms",
                  "Euro zone to Greece: No rescue without reforms",
                  "0.52",
                  "0.5646466612815857"
                ],
                [
                  "45",
                  "sts_train_5222",
                  "Obama condemns Egypt violence, cancels military exercises",
                  "Pakistan condemns violence in Egypt",
                  "0.16",
                  "0.1827541291713714"
                ],
                [
                  "46",
                  "sts_train_2215",
                  "I thought that was mostly just the Dutch.",
                  "It is mostly just the Dutch.",
                  "0.8",
                  "0.7515009641647339"
                ],
                [
                  "47",
                  "sts_train_2233",
                  "Irreligion that does that I have a problem.",
                  "Religion that doesn't do that I don't have a problem with.",
                  "0.32",
                  "0.3700679242610931"
                ],
                [
                  "48",
                  "sts_train_2234",
                  "If I'm angry, it will show up in one of those scans..",
                  "If I'm hyper active, it will show up in one of those scans..",
                  "0.6400000000000001",
                  "0.693057119846344"
                ],
                [
                  "49",
                  "sick_train_1326",
                  "A horse and its rider are not leaping over a barrier",
                  "A horse is leaping a hurdle and has a rider on its back",
                  "0.92",
                  "0.9793878197669984"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 12833
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>score</th>\n",
              "      <th>BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sts_train_4024</td>\n",
              "      <td>Sudan Blocks YouTube Over Anti-Islam Film</td>\n",
              "      <td>Pakistan's PM orders YouTube halt over anti-Is...</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.556423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sts_train_1409</td>\n",
              "      <td>A man riding a white horse.</td>\n",
              "      <td>A woman leading a white horse.</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.334312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sts_train_3397</td>\n",
              "      <td>Mr Morse is charged with assault and Mr Darvis...</td>\n",
              "      <td>His partner Bijan Darvish is charged with fili...</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.469501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sts_train_1532</td>\n",
              "      <td>A girl playing is a pile of colorful balls.</td>\n",
              "      <td>A little girl plays in a pit of colorful balls.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.008758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sick_train_1874</td>\n",
              "      <td>A person in a black jacket is doing tricks on ...</td>\n",
              "      <td>A man in a black jacket is doing tricks on a m...</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.943288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12828</th>\n",
              "      <td>sick_train_6323</td>\n",
              "      <td>A player of soccer is scoring a goal</td>\n",
              "      <td>Soccer players are kicking a soccer ball into ...</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.823367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12829</th>\n",
              "      <td>sick_train_87</td>\n",
              "      <td>The man and woman are strolling</td>\n",
              "      <td>The man and woman are walking</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.919968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12830</th>\n",
              "      <td>sts_train_3897</td>\n",
              "      <td>S. Africa's former president Mandela discharge...</td>\n",
              "      <td>Mandela Discharged From Hospital</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.864671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12831</th>\n",
              "      <td>sick_train_718</td>\n",
              "      <td>A large brown cat is jumping over a red hurdle</td>\n",
              "      <td>A large brown dog is jumping over a red hurdle</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.742021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12832</th>\n",
              "      <td>sts_train_574</td>\n",
              "      <td>A girl makes up her bed.</td>\n",
              "      <td>A young girl makes her bed.</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.891920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12833 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id                                                 s1  \\\n",
              "0       sts_train_4024          Sudan Blocks YouTube Over Anti-Islam Film   \n",
              "1       sts_train_1409                        A man riding a white horse.   \n",
              "2       sts_train_3397  Mr Morse is charged with assault and Mr Darvis...   \n",
              "3       sts_train_1532        A girl playing is a pile of colorful balls.   \n",
              "4      sick_train_1874  A person in a black jacket is doing tricks on ...   \n",
              "...                ...                                                ...   \n",
              "12828  sick_train_6323               A player of soccer is scoring a goal   \n",
              "12829    sick_train_87                    The man and woman are strolling   \n",
              "12830   sts_train_3897  S. Africa's former president Mandela discharge...   \n",
              "12831   sick_train_718     A large brown cat is jumping over a red hurdle   \n",
              "12832    sts_train_574                           A girl makes up her bed.   \n",
              "\n",
              "                                                      s2  score      BERT  \n",
              "0      Pakistan's PM orders YouTube halt over anti-Is...   0.56  0.556423  \n",
              "1                         A woman leading a white horse.   0.36  0.334312  \n",
              "2      His partner Bijan Darvish is charged with fili...   0.55  0.469501  \n",
              "3        A little girl plays in a pit of colorful balls.   1.00  1.008758  \n",
              "4      A man in a black jacket is doing tricks on a m...   0.98  0.943288  \n",
              "...                                                  ...    ...       ...  \n",
              "12828  Soccer players are kicking a soccer ball into ...   0.86  0.823367  \n",
              "12829                      The man and woman are walking   0.90  0.919968  \n",
              "12830                   Mandela Discharged From Hospital   0.84  0.864671  \n",
              "12831     A large brown dog is jumping over a red hurdle   0.68  0.742021  \n",
              "12832                        A young girl makes her bed.   0.88  0.891920  \n",
              "\n",
              "[12833 rows x 5 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df = train_df[['id', 's1', 's2', 'score', 'BERT']]\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "train_df.to_csv('./train_df.csv')\n",
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y-1uc4_o5Z5o",
        "outputId": "939f55bf-52e6-4d20-ec05-b7dadac3abf9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s1",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "s2",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "BERT",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "0d92e227-9de6-4540-bf44-97dff0255efc",
              "rows": [
                [
                  "0",
                  "sick_test_822",
                  "A woman is talking to a man",
                  "A man is talking to a woman",
                  "0.9",
                  "0.9745688438415528"
                ],
                [
                  "1",
                  "sts_test_111",
                  "A man is putting garlic on some bread slices.",
                  "A man is sprinkling seasoning on several split and buttered loaves of bread.",
                  "0.4",
                  "0.691741943359375"
                ],
                [
                  "2",
                  "sts_test_502",
                  "A bike is next to a couple women.",
                  "A child next to a bike.",
                  "0.4",
                  "0.7651089429855347"
                ],
                [
                  "3",
                  "sick_test_1253",
                  "A man is playing a bamboo flute",
                  "A flute is being played by the man",
                  "0.86",
                  "0.964098870754242"
                ],
                [
                  "4",
                  "sick_test_1967",
                  "A woman on a rock is lying on a blanket and reading a book",
                  "A woman is rocking over a blanket lying on someone reading a book",
                  "0.54",
                  "0.9460808634757996"
                ],
                [
                  "5",
                  "sick_test_464",
                  "The small bee is landing on a bunch of yellow flowers",
                  "A bee is clinging to a yellow flower",
                  "0.72",
                  "0.7897123694419861"
                ],
                [
                  "6",
                  "sts_test_1066",
                  "Kids, adults, booksellers and postal workers all are preparing for \"Harry Potter and the Order of the Phoenix.\"",
                  "The crates are full of hardback copies of \"Harry Potter and the Order of the Phoenix.\"",
                  "0.44",
                  "0.5503799915313721"
                ],
                [
                  "7",
                  "sick_test_440",
                  "A woman in a bikini is pulling a dog on a leash at the beach",
                  "A woman in a bikini is pulling a cat on a leash at the beach",
                  "0.78",
                  "0.7523176074028015"
                ],
                [
                  "8",
                  "sick_test_732",
                  "A crowd of people is near the water",
                  "A group of children wearing the same clothes is waiting at a gate and one is kissing the mother",
                  "0.32",
                  "0.469178169965744"
                ],
                [
                  "9",
                  "sick_test_997",
                  "A black dog and a small white and black dog are looking up at a kitchen countertop",
                  "A large dog and a small dog are standing next to the kitchen counter and are investigating",
                  "0.8400000000000001",
                  "0.6681010723114014"
                ],
                [
                  "10",
                  "sick_test_29",
                  "A child is amazedly experiencing a new world",
                  "A child is experiencing a new world",
                  "0.9",
                  "0.9821283221244812"
                ],
                [
                  "11",
                  "sick_test_139",
                  "The herd of caribous is crossing a road",
                  "The herd of caribous is not crossing a road",
                  "0.6799999999999999",
                  "0.8128095865249634"
                ],
                [
                  "12",
                  "sts_test_1060",
                  "Taiwan has attempted to gain observer status to the United Nations-affiliated WHO for seven years, but again was rebuffed March 19 at its annual conference in Geneva.",
                  "It has sought observer status for seven years, but was again rebuffed May 19 at the annual WHO conference in Geneva.",
                  "0.65",
                  "0.6053591370582581"
                ],
                [
                  "13",
                  "sick_test_1405",
                  "A light brown dog is running in the water",
                  "A tan dog is playing in the water on the bank of a pond",
                  "0.8",
                  "0.693382203578949"
                ],
                [
                  "14",
                  "sick_test_1415",
                  "A woman is taking eggs out of a bowl",
                  "A woman is placing skewers onto a rack",
                  "0.38",
                  "0.283557116985321"
                ],
                [
                  "15",
                  "sts_test_1319",
                  "What the Papers Say, Aug. 19, 2013",
                  "What the Papers Say, Dec. 30, 2013",
                  "0.534",
                  "0.4518528282642364"
                ],
                [
                  "16",
                  "sick_test_1412",
                  "Pedestrians and cars are moving through a traffic jam in a big city",
                  "Some people and vehicles are on a crowded street",
                  "0.64",
                  "0.8382599949836731"
                ],
                [
                  "17",
                  "sick_test_343",
                  "Two girls are playing guitar",
                  "Two men are talking",
                  "0.307",
                  "0.1787436753511428"
                ],
                [
                  "18",
                  "sick_test_436",
                  "A boy and a girl are naked",
                  "A boy and a girl in swimsuits are wearing arm floats",
                  "0.52",
                  "0.5309771299362183"
                ],
                [
                  "19",
                  "sick_test_763",
                  "A small man is sitting in a military accessories store",
                  "The person is slicing onions",
                  "0.2",
                  "0.2244737148284912"
                ],
                [
                  "20",
                  "sick_test_709",
                  "Runners are racing down a track",
                  "Men are running a race",
                  "0.78",
                  "0.7459227442741394"
                ],
                [
                  "21",
                  "sick_test_1457",
                  "A man and a child are kayaking through gentle waters",
                  "A yellow kayak is being ridden by a man and a young boy",
                  "0.8800000000000001",
                  "0.72077876329422"
                ],
                [
                  "22",
                  "sick_test_1055",
                  "A woman on a boulder is lying on a blanket and reading a book",
                  "A seated woman is singing a song and playing the guitar",
                  "0.52",
                  "0.3981631100177765"
                ],
                [
                  "23",
                  "sts_test_558",
                  "Six children are cleaning a room.",
                  "Two male children cleaning up leaves in a parking lot.",
                  "0.32",
                  "0.4277808368206024"
                ],
                [
                  "24",
                  "sick_test_1319",
                  "Two little boys are playing outside with a soccer ball on the green grass",
                  "There are no little boys playing outside with a soccer ball on the green grass",
                  "0.64",
                  "0.8411417007446289"
                ],
                [
                  "25",
                  "sick_test_344",
                  "The young boys are playing outdoors and the man is smiling nearby",
                  "There is no boy playing outdoors and there is no man smiling",
                  "0.72",
                  "0.926966428756714"
                ],
                [
                  "26",
                  "sick_test_323",
                  "Boys are dancing in front of some people",
                  "Two men are doing a funny skit with a boxer in front of a crowd of people",
                  "0.44",
                  "0.3026833534240722"
                ],
                [
                  "27",
                  "sick_test_814",
                  "A woman is adding ingredients to a big bowl",
                  "A woman is cracking some eggs into a bowl",
                  "0.86",
                  "0.6002654433250427"
                ],
                [
                  "28",
                  "sick_test_132",
                  "Dirt bikers are not riding on a trail",
                  "Dirt bikers are riding on a trail",
                  "0.8",
                  "0.7789063453674316"
                ],
                [
                  "29",
                  "sts_test_1228",
                  "Nelson Mandela in Hospital for Tests",
                  "South Africa: Mandela in hospital for tests",
                  "0.92",
                  "0.9499765634536744"
                ],
                [
                  "30",
                  "sick_test_1514",
                  "A band is performing on a stage",
                  "A band is playing onstage",
                  "0.98",
                  "1.08297860622406"
                ],
                [
                  "31",
                  "sick_test_1585",
                  "The man is cutting cooked octopus",
                  "A woman is chopping up an octopus",
                  "0.817",
                  "0.5959733128547668"
                ],
                [
                  "32",
                  "sick_test_550",
                  "A middle eastern man is standing with the back against a lamp post near to other people",
                  "A middle eastern man is standing against a lamp post near to other people",
                  "0.9",
                  "0.9108361601829528"
                ],
                [
                  "33",
                  "sick_test_1851",
                  "A man is drawing",
                  "There is no man drawing",
                  "0.76",
                  "0.8327609896659851"
                ],
                [
                  "34",
                  "sick_test_509",
                  "A man in a hat is standing outside of a green jeep",
                  "A man in a hat is standing outside of a green vehicle",
                  "0.9",
                  "0.8797928690910339"
                ],
                [
                  "35",
                  "sts_test_75",
                  "The man is using a camera to hammer a nail.",
                  "Someone is banging a camera lense against a nail.",
                  "0.52",
                  "0.7750473022460938"
                ],
                [
                  "36",
                  "sick_test_387",
                  "The person with the green shirt is jumping high over the grass",
                  "A young boy is jumping in the air with his knees bent and arms spread",
                  "0.6",
                  "0.6332209706306458"
                ],
                [
                  "37",
                  "sick_test_1911",
                  "A girl in a band is playing the flute",
                  "A girl in a band is playing an instrument",
                  "0.8800000000000001",
                  "0.8215572834014893"
                ],
                [
                  "38",
                  "sick_test_782",
                  "A yellow dog is running down a path covered by sand",
                  "A golden retriever is running",
                  "0.72",
                  "0.5727254748344421"
                ],
                [
                  "39",
                  "sick_test_417",
                  "A small dog is lying on a bed",
                  "A small dog is lying under the bed",
                  "0.62",
                  "0.9156191945075988"
                ],
                [
                  "40",
                  "sick_test_662",
                  "A man is not cutting a potato",
                  "A man is cutting a potato",
                  "0.72",
                  "0.8191822171211243"
                ],
                [
                  "41",
                  "sick_test_1037",
                  "A person is stupidly throwing a cat at the ceiling",
                  "A person is throwing a cat at the ceiling",
                  "0.8800000000000001",
                  "0.907307505607605"
                ],
                [
                  "42",
                  "sts_test_1302",
                  "Saudi Arabia gets a seat at the UN Security Council",
                  "Saudi Arabia rejects seat on UN Security Council",
                  "0.5599999999999999",
                  "0.6330841183662415"
                ],
                [
                  "43",
                  "sick_test_1524",
                  "Four people are difficultly walking with difficulty across thick snow and the sun is setting",
                  "Four people are walking across thick snow and the sun is setting",
                  "0.92",
                  "0.919081687927246"
                ],
                [
                  "44",
                  "sick_test_140",
                  "An old woman is wearing a rose patterned shirt and is clumsily carrying two newspapers",
                  "The woman is wearing sunglasses of large size and is holding newspapers in both hands",
                  "0.7",
                  "0.656484842300415"
                ],
                [
                  "45",
                  "sts_test_960",
                  "Martin, 58, will be freed today after serving two thirds of his five-year sentence for the manslaughter of 16-year-old Fred Barras.",
                  "Martin served two thirds of a five-year sentence for the manslaughter of Barras and for wounding Fearon.",
                  "0.6000000000000001",
                  "0.580322802066803"
                ],
                [
                  "46",
                  "sick_test_189",
                  "A small monkey is walking in the river",
                  "A small monkey is walking through water",
                  "0.86",
                  "0.8558796644210815"
                ],
                [
                  "47",
                  "sick_test_518",
                  "Some meat is being stitched together by a woman",
                  "Some meat is being cut into pieces by a woman",
                  "0.65",
                  "0.8556027412414551"
                ],
                [
                  "48",
                  "sick_test_607",
                  "The woman is chopping garlic",
                  "The woman is not chopping garlic",
                  "0.6",
                  "0.8609710335731506"
                ],
                [
                  "49",
                  "sick_test_1712",
                  "A surfer is leaning on a surfboard",
                  "The person is wearing a wetsuit and is riding a surfboard",
                  "0.597",
                  "0.6352059245109558"
                ]
              ],
              "shape": {
                "columns": 5,
                "rows": 3347
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>score</th>\n",
              "      <th>BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sick_test_822</td>\n",
              "      <td>A woman is talking to a man</td>\n",
              "      <td>A man is talking to a woman</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.974569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sts_test_111</td>\n",
              "      <td>A man is putting garlic on some bread slices.</td>\n",
              "      <td>A man is sprinkling seasoning on several split...</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.691742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sts_test_502</td>\n",
              "      <td>A bike is next to a couple women.</td>\n",
              "      <td>A child next to a bike.</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.765109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sick_test_1253</td>\n",
              "      <td>A man is playing a bamboo flute</td>\n",
              "      <td>A flute is being played by the man</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.964099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sick_test_1967</td>\n",
              "      <td>A woman on a rock is lying on a blanket and re...</td>\n",
              "      <td>A woman is rocking over a blanket lying on som...</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.946081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3342</th>\n",
              "      <td>sick_test_1099</td>\n",
              "      <td>A woman is collecting tap water in a mug</td>\n",
              "      <td>There is no boy filling a pitcher with water</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.498875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3343</th>\n",
              "      <td>sts_test_559</td>\n",
              "      <td>There is a cook preparing food.</td>\n",
              "      <td>A cook is making food.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.987018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3344</th>\n",
              "      <td>sick_test_1212</td>\n",
              "      <td>A young boy is playing a guitar</td>\n",
              "      <td>A boy is playing guitar</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.898162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3345</th>\n",
              "      <td>sick_test_1101</td>\n",
              "      <td>A dog, which is small, is playing on the green...</td>\n",
              "      <td>A dog is near a ball colored in red, which is ...</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.602705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3346</th>\n",
              "      <td>sts_test_881</td>\n",
              "      <td>Bremer said one initiative is to launch a US$7...</td>\n",
              "      <td>Bremer said he would launch a $70-million prog...</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.670134</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3347 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id                                                 s1  \\\n",
              "0      sick_test_822                        A woman is talking to a man   \n",
              "1       sts_test_111      A man is putting garlic on some bread slices.   \n",
              "2       sts_test_502                  A bike is next to a couple women.   \n",
              "3     sick_test_1253                    A man is playing a bamboo flute   \n",
              "4     sick_test_1967  A woman on a rock is lying on a blanket and re...   \n",
              "...              ...                                                ...   \n",
              "3342  sick_test_1099           A woman is collecting tap water in a mug   \n",
              "3343    sts_test_559                    There is a cook preparing food.   \n",
              "3344  sick_test_1212                    A young boy is playing a guitar   \n",
              "3345  sick_test_1101  A dog, which is small, is playing on the green...   \n",
              "3346    sts_test_881  Bremer said one initiative is to launch a US$7...   \n",
              "\n",
              "                                                     s2  score      BERT  \n",
              "0                           A man is talking to a woman   0.90  0.974569  \n",
              "1     A man is sprinkling seasoning on several split...   0.40  0.691742  \n",
              "2                               A child next to a bike.   0.40  0.765109  \n",
              "3                    A flute is being played by the man   0.86  0.964099  \n",
              "4     A woman is rocking over a blanket lying on som...   0.54  0.946081  \n",
              "...                                                 ...    ...       ...  \n",
              "3342       There is no boy filling a pitcher with water   0.52  0.498875  \n",
              "3343                             A cook is making food.   1.00  0.987018  \n",
              "3344                            A boy is playing guitar   0.86  0.898162  \n",
              "3345  A dog is near a ball colored in red, which is ...   0.48  0.602705  \n",
              "3346  Bremer said he would launch a $70-million prog...   0.72  0.670134  \n",
              "\n",
              "[3347 rows x 5 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = test_df[['id', 's1', 's2', 'score', 'BERT']]\n",
        "\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "test_df.to_csv('./test_df.csv')\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m9ikgz525Z5o"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('./train_df.csv')\n",
        "test_df = pd.read_csv('./test_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dVymjpfZ5Z5o"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac5ba80cec3641c997756389d29385c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89b341caa8d745869d3526f3bb53bc77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36c3b53eb98a48f1b2b5571f94f15df4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a55026156aa04d66bd5df81f5800f4ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiobHziV5Z5p",
        "outputId": "230678d7-ae24-4edf-c412-257252333139"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'microsoft/MiniLM-L12-H384-uncased',\n",
        "    num_labels=1  # for regression\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywTLtTty5Z5p",
        "outputId": "571490e3-af8d-40f9-e7ca-7f422b46e9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106\n"
          ]
        }
      ],
      "source": [
        "# compute the sequence length using 95% samples logic\n",
        "lengths = []\n",
        "for _, row in train_df.iterrows():\n",
        "    lengths.append(len(row['s1']))\n",
        "    lengths.append(len(row['s2']))\n",
        "\n",
        "lengths.sort()\n",
        "MAX_LEN = lengths[int(0.95*len(lengths))]\n",
        "print(MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7yUGHALS5Z5q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Custom loss function\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, outputs, labels, soft_labels):\n",
        "        preds = outputs.logits.view(-1)\n",
        "        loss_hard = self.mse(preds, labels)\n",
        "        loss_soft = self.mse(preds, soft_labels)\n",
        "        return self.alpha * loss_hard + (1 - self.alpha) * loss_soft\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_sentences_to_features(sentences, tokenizer, max_len):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    token_type_ids = []\n",
        "\n",
        "    for i in range(0, len(sentences), 2):\n",
        "        encoded_dict = tokenizer.encode_plus(sentences[i], sentences[i+1], add_special_tokens=True, max_length=max_len, truncation=True, padding='max_length', return_attention_mask=True, return_tensors='pt', truncation_strategy='longest_first')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks, token_type_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Lex7JyK95Z5q"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     x_train.append(row[\u001b[33m'\u001b[39m\u001b[33ms1\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      8\u001b[39m     x_train.append(row[\u001b[33m'\u001b[39m\u001b[33ms2\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m input_ids, attention_masks, token_type_ids = convert_sentences_to_features(x_train, \u001b[43mtokenizer\u001b[49m, max_len=MAX_LEN)\n\u001b[32m     11\u001b[39m y_train = torch.tensor(train_df[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m], dtype=torch.float)\n\u001b[32m     13\u001b[39m soft_labels = torch.tensor(train_df[\u001b[33m'\u001b[39m\u001b[33mBERT\u001b[39m\u001b[33m'\u001b[39m], dtype=torch.float)\n",
            "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# train_dataset = .map(preprocess_function, batched=False)\n",
        "# test_dataset = test_dataset.map(preprocess_function, batched=False)\n",
        "\n",
        "x_train = []\n",
        "\n",
        "for _, row in train_df.iterrows():\n",
        "    x_train.append(row['s1'])\n",
        "    x_train.append(row['s2'])\n",
        "\n",
        "input_ids, attention_masks, token_type_ids = convert_sentences_to_features(x_train, tokenizer, max_len=MAX_LEN)\n",
        "y_train = torch.tensor(train_df['score'], dtype=torch.float)\n",
        "\n",
        "soft_labels = torch.tensor(train_df['BERT'], dtype=torch.float)\n",
        "\n",
        "data_dict = {\n",
        "    'input_ids': input_ids.to(device),\n",
        "    'attention_mask': attention_masks.to(device),\n",
        "    'token_type_ids': token_type_ids.to(device),\n",
        "    'labels': y_train.to(device),\n",
        "    'soft_labels': soft_labels.to(device),\n",
        "}\n",
        "\n",
        "train_dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "x_test = []\n",
        "\n",
        "for _, row in test_df.iterrows():\n",
        "    x_test.append(row['s1'])\n",
        "    x_test.append(row['s2'])\n",
        "\n",
        "input_ids, attention_masks, token_type_ids = convert_sentences_to_features(x_test, tokenizer, max_len=MAX_LEN)\n",
        "y_test = torch.tensor(test_df['score'], dtype=torch.float)\n",
        "\n",
        "soft_labels = torch.tensor(test_df['BERT'], dtype=torch.float)\n",
        "\n",
        "data_dict = {\n",
        "    'input_ids': input_ids.to(device),\n",
        "    'attention_mask': attention_masks.to(device),\n",
        "    'token_type_ids': token_type_ids.to(device),\n",
        "    'labels': y_test.to(device),\n",
        "    'soft_labels': soft_labels.to(device),\n",
        "}\n",
        "\n",
        "test_dataset = Dataset.from_dict(data_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "G96d25TM7efB"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3ualQnD5Z5r",
        "outputId": "d3c7039a-0040-44f8-b225-dc264ec7b731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'token_type_ids', 'labels', 'soft_labels'],\n",
            "    num_rows: 12833\n",
            "})\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'token_type_ids', 'labels', 'soft_labels'],\n",
            "    num_rows: 3347\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "# Custom Trainer with distillation loss\n",
        "class DistillationTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        # labels = inputs.pop(\"labels\")\n",
        "        # print(inputs)\n",
        "        labels = inputs[\"labels\"]  # ✅ keep this; Trainer ensures it's here\n",
        "        # soft_labels = inputs.get(\"soft_labels\", None)  # ✅ safe access\n",
        "        # print(soft_labels)\n",
        "        soft_labels = inputs.pop(\"soft_labels\")\n",
        "        outputs = model(**inputs)\n",
        "        loss_fct = DistillationLoss(alpha=0.5)\n",
        "        loss = loss_fct(outputs, labels, soft_labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./tinybert-distilled\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=7,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "print(train_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "trainer = DistillationTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    # data_collator=data_collator,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "QCxWzyc15Z5s",
        "outputId": "e5630662-73a1-46f2-b513-708f9b869882"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5621' max='5621' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5621/5621 11:09, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.032400</td>\n",
              "      <td>0.018016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.016369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.010400</td>\n",
              "      <td>0.016943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.017203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.014932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.015179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.004800</td>\n",
              "      <td>0.014810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5621, training_loss=0.010552009427447778, metrics={'train_runtime': 669.8751, 'train_samples_per_second': 134.101, 'train_steps_per_second': 8.391, 'total_flos': 1225067459413476.0, 'train_loss': 0.010552009427447778, 'epoch': 7.0})"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "RRsd32PW8K42"
      },
      "outputs": [],
      "source": [
        "torch.save(trainer.model, 'models/model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3U8hH_p9hui",
        "outputId": "4c93bd51-3480-4624-b1ba-22964920a857"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_24691/3635517369.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('models/model.pt', map_location=torch.device('cpu'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 384)\n",
              "      (token_type_embeddings): Embedding(2, 384)\n",
              "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=384, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = torch.load('models/model.pt', map_location=torch.device('cpu'))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1d3aNncqCr4t"
      },
      "outputs": [],
      "source": [
        "best_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "611f5a5a128d4112bace039859461687",
            "3244686b64d6406c824eba76c090be6a",
            "678c0cd31075496486abd9fbfa77ccbb",
            "1725e09562e14127919759323668175b",
            "5630387e06e94828ba91fd46883b1a45",
            "7b506f02ae4845ecae7be438c4e569c0",
            "591fc5ef432842a9a1ff36147ab7d61a",
            "908a5ba9b0ab4da5869d503a0d793032",
            "c59fe1d27ea44103a87cd36376b0d57d",
            "75f25d31edf94d62b7376977e806fcec",
            "c8113fa0c02442c984226a5e424f4e35"
          ]
        },
        "id": "QNJuoBJb8q7B",
        "outputId": "63a1689a-bfa3-4bb8-d4ea-98ddb4cbeddd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6663ed1d86ad49a0af8c11123283892b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/210 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved in results.csv\n",
            "Correlation between expected and predicted similarity scores: 0.8943392931119134\n"
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "testdata = pd.read_csv('test_df.csv')\n",
        "\n",
        "x_test = []\n",
        "for _, row in testdata.iterrows():\n",
        "    x_test.append(row['s1'])\n",
        "    x_test.append(row['s2'])\n",
        "\n",
        "input_ids, attention_masks, token_type_ids = convert_sentences_to_features(x_test, tokenizer, MAX_LEN)\n",
        "y_test = torch.tensor(testdata['score'], dtype=torch.float)\n",
        "\n",
        "testset = TensorDataset(input_ids, attention_masks, token_type_ids, y_test)\n",
        "testloader = DataLoader(testset, batch_size=16, shuffle=False)\n",
        "\n",
        "df_raw = pd.read_csv('../../test.csv')\n",
        "id = df_raw['id'].values\n",
        "s1_raw = df_raw['s1'].values\n",
        "s2_raw = df_raw['s2'].values\n",
        "y_raw = df_raw['score'].values\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    for _, batch in tqdm(enumerate(testloader), total=len(testloader)):\n",
        "        input_ids, attention_masks, _, labels = tuple(t for t in batch)\n",
        "        outputs = best_model(input_ids.to(device), token_type_ids=None, attention_mask=attention_masks.to(device), labels=labels.to(device))\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend([row[0] for row in outputs[1].tolist()])\n",
        "    # print(len(train_embeddings1))\n",
        "    # output = model(train_embeddings1, train_embeddings2)\n",
        "    # y_pred = output.squeeze()\n",
        "    # # y_pred = model(s1_train, s2_train)\n",
        "    # # y_pred = y_pred.numpy()\n",
        "    # # y_pred = np.squeeze(y_pred)\n",
        "    # # y_pred = np.clip(y_pred, 0, 5)\n",
        "    # print(id.shape, s1_raw.shape, y_raw.shape, len(y_pred))\n",
        "    results = pd.DataFrame({'id': id, 'sentence1': s1_raw, 'sentence2': s2_raw, 'similarity': y_raw, 'predicted_similarity': y_pred})\n",
        "    results.to_csv(f'Results/test.csv', index=False)\n",
        "    print(f'Predictions saved in results.csv')\n",
        "\n",
        "correlation = pd.Series(y_raw).corr(pd.Series(y_pred))\n",
        "print('Correlation between expected and predicted similarity scores:', correlation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "43fcefed3c464d8b8ad8c39baeefa7da",
            "c56311e15ece4c01969097f7e854b454",
            "cb1f92eb37a4467b89a6e128bd15ef3d",
            "0a281689c24c4c46a1feb9cc6086dcac",
            "e188892c6be048d3b4f8ad5c1675e1ed",
            "80b00886a6144e6ba3ac792af070ed24",
            "72b49b8708fd43259aedbe5bc373d61f",
            "66d5ff4f9efc4602b5604e4139797f9f",
            "1ed52fa19c144859b5b0b770ea17ed69",
            "68a43dec9b364e7f97e36b8111c46a5e",
            "bf1f106e62444a7689c9d265e134d5fe"
          ]
        },
        "id": "Kz5hwEEi_4ms",
        "outputId": "77845f18-a17f-414a-b54d-e18670da99fd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43fcefed3c464d8b8ad8c39baeefa7da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/803 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved in results.csv\n",
            "Correlation between expected and predicted similarity scores: 0.972750803642151\n"
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "traindata = pd.read_csv('train_df.csv')\n",
        "\n",
        "x_train = []\n",
        "for _, row in traindata.iterrows():\n",
        "    x_train.append(row['s1'])\n",
        "    x_train.append(row['s2'])\n",
        "\n",
        "input_ids, attention_masks, token_type_ids = convert_sentences_to_features(x_train, tokenizer, MAX_LEN)\n",
        "y_train = torch.tensor(traindata['score'], dtype=torch.float)\n",
        "\n",
        "trainset = TensorDataset(input_ids, attention_masks, token_type_ids, y_train)\n",
        "trainloader = DataLoader(trainset, batch_size=16, shuffle=False)\n",
        "\n",
        "df_raw = pd.read_csv('./train.csv')\n",
        "id = df_raw['id'].values\n",
        "s1_raw = df_raw['s1'].values\n",
        "s2_raw = df_raw['s2'].values\n",
        "y_raw = df_raw['score'].values\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "best_model.eval()\n",
        "with torch.no_grad():\n",
        "    for _, batch in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "        input_ids, attention_masks, _, labels = tuple(t for t in batch)\n",
        "        outputs = best_model(input_ids.to(device), token_type_ids=None, attention_mask=attention_masks.to(device), labels=labels.to(device))\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend([row[0] for row in outputs[1].tolist()])\n",
        "    # print(len(train_embeddings1))\n",
        "    # output = model(train_embeddings1, train_embeddings2)\n",
        "    # y_pred = output.squeeze()\n",
        "    # # y_pred = model(s1_train, s2_train)\n",
        "    # # y_pred = y_pred.numpy()\n",
        "    # # y_pred = np.squeeze(y_pred)\n",
        "    # # y_pred = np.clip(y_pred, 0, 5)\n",
        "    # print(id.shape, s1_raw.shape, y_raw.shape, len(y_pred))\n",
        "    results = pd.DataFrame({'id': id, 'sentence1': s1_raw, 'sentence2': s2_raw, 'similarity': y_raw, 'predicted_similarity': y_pred})\n",
        "    results.to_csv(f'Results/train.csv', index=False)\n",
        "    print(f'Predictions saved in results.csv')\n",
        "\n",
        "correlation = pd.Series(y_raw).corr(pd.Series(y_pred))\n",
        "print('Correlation between expected and predicted similarity scores:', correlation)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a281689c24c4c46a1feb9cc6086dcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a43dec9b364e7f97e36b8111c46a5e",
            "placeholder": "​",
            "style": "IPY_MODEL_bf1f106e62444a7689c9d265e134d5fe",
            "value": " 803/803 [00:24&lt;00:00, 33.24it/s]"
          }
        },
        "1725e09562e14127919759323668175b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75f25d31edf94d62b7376977e806fcec",
            "placeholder": "​",
            "style": "IPY_MODEL_c8113fa0c02442c984226a5e424f4e35",
            "value": " 210/210 [00:06&lt;00:00, 33.51it/s]"
          }
        },
        "1ed52fa19c144859b5b0b770ea17ed69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3244686b64d6406c824eba76c090be6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b506f02ae4845ecae7be438c4e569c0",
            "placeholder": "​",
            "style": "IPY_MODEL_591fc5ef432842a9a1ff36147ab7d61a",
            "value": "100%"
          }
        },
        "43fcefed3c464d8b8ad8c39baeefa7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c56311e15ece4c01969097f7e854b454",
              "IPY_MODEL_cb1f92eb37a4467b89a6e128bd15ef3d",
              "IPY_MODEL_0a281689c24c4c46a1feb9cc6086dcac"
            ],
            "layout": "IPY_MODEL_e188892c6be048d3b4f8ad5c1675e1ed"
          }
        },
        "5630387e06e94828ba91fd46883b1a45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591fc5ef432842a9a1ff36147ab7d61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "611f5a5a128d4112bace039859461687": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3244686b64d6406c824eba76c090be6a",
              "IPY_MODEL_678c0cd31075496486abd9fbfa77ccbb",
              "IPY_MODEL_1725e09562e14127919759323668175b"
            ],
            "layout": "IPY_MODEL_5630387e06e94828ba91fd46883b1a45"
          }
        },
        "66d5ff4f9efc4602b5604e4139797f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678c0cd31075496486abd9fbfa77ccbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908a5ba9b0ab4da5869d503a0d793032",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c59fe1d27ea44103a87cd36376b0d57d",
            "value": 210
          }
        },
        "68a43dec9b364e7f97e36b8111c46a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b49b8708fd43259aedbe5bc373d61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75f25d31edf94d62b7376977e806fcec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b506f02ae4845ecae7be438c4e569c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b00886a6144e6ba3ac792af070ed24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908a5ba9b0ab4da5869d503a0d793032": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1f106e62444a7689c9d265e134d5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c56311e15ece4c01969097f7e854b454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80b00886a6144e6ba3ac792af070ed24",
            "placeholder": "​",
            "style": "IPY_MODEL_72b49b8708fd43259aedbe5bc373d61f",
            "value": "100%"
          }
        },
        "c59fe1d27ea44103a87cd36376b0d57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8113fa0c02442c984226a5e424f4e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb1f92eb37a4467b89a6e128bd15ef3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d5ff4f9efc4602b5604e4139797f9f",
            "max": 803,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed52fa19c144859b5b0b770ea17ed69",
            "value": 803
          }
        },
        "e188892c6be048d3b4f8ad5c1675e1ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
